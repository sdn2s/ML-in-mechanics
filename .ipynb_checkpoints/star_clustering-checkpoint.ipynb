{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b64b461",
   "metadata": {},
   "source": [
    "\n",
    "# Кластеризация звезд, галактик и квазаров\n",
    "\n",
    "Цель: выполнить EDA, подготовку данных, кластеризацию разными алгоритмами и сравнить результаты с истинными метками.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee6bf5",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Импорт библиотек\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, v_measure_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8141d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Загрузка данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e63535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = Path(\"star_classification.csv\")\n",
    "assert path.exists(), \"CSV не найден\"\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9427198",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Распределение классов и проверка качества данных\n",
    "\n",
    "В исходных данных встречаются значения `-9999` — это технический код пропуска. \n",
    "Если строить гистограммы без обработки, получается один «столбик», потому что диапазон резко расширяется.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Замена технических пропусков на NaN\n",
    "for col in ['u','g','r','i','z']:\n",
    "    df.loc[df[col] == -9999, col] = np.nan\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "print(\"Пропуски по фотометрии:\")\n",
    "print(df[['u','g','r','i','z']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f045028",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EDA: распределения и корреляции\n",
    "\n",
    "Ниже гистограммы строятся уже без `-9999`, поэтому они отражают реальные диапазоны значений.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "sns.histplot(df['u'].dropna(), bins=40, ax=axes[0])\n",
    "axes[0].set_title(\"Распределение u\")\n",
    "\n",
    "sns.histplot(df['g'].dropna(), bins=40, ax=axes[1])\n",
    "axes[1].set_title(\"Распределение g\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef884188",
   "metadata": {},
   "source": [
    "\n",
    "### Корреляции\n",
    "\n",
    "Для фотометрических полос ожидаемо сильная положительная корреляция между соседними диапазонами (u–g, g–r и т.д.).\n",
    "Корреляция `redshift` с полосами помогает отделять объекты по космологической дистанции.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_features = ['u','g','r','i','z','redshift']\n",
    "\n",
    "# чистая таблица без пропусков в выбранных признаках\n",
    "df_clean = df.dropna(subset=cluster_features)\n",
    "\n",
    "corr = df_clean[cluster_features].corr(numeric_only=True)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, square=True)\n",
    "plt.title(\"Корреляции признаков\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158fb2c4",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Подготовка данных\n",
    "\n",
    "Для кластеризации используем фотометрию и `redshift`. ID‑поля исключаем.\n",
    "Выбросы обрезаем по 1/99‑квантилям, затем стандартизируем.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef004fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_raw = df_clean[cluster_features]\n",
    "\n",
    "# Отсечение выбросов\n",
    "lower = X_raw.quantile(0.01)\n",
    "upper = X_raw.quantile(0.99)\n",
    "X_clipped = X_raw.clip(lower, upper, axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_clipped)\n",
    "\n",
    "print(\"Размерность после очистки:\", X_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e710533",
   "metadata": {},
   "source": [
    "\n",
    "## 6. PCA: объясненная дисперсия и состав первой компоненты\n",
    "\n",
    "Покажем, сколько дисперсии объясняет каждая компонента, и какие признаки сильнее всего формируют первую компоненту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca_full = PCA(n_components=len(cluster_features), random_state=42)\n",
    "X_pca_full = pca_full.fit_transform(X_scaled)\n",
    "\n",
    "explained = pd.Series(pca_full.explained_variance_ratio_,\n",
    "                      index=[f\"PC{i+1}\" for i in range(len(cluster_features))])\n",
    "print(explained)\n",
    "\n",
    "loadings_pc1 = pd.Series(pca_full.components_[0], index=cluster_features)\n",
    "loadings_pc1 = loadings_pc1.reindex(loadings_pc1.abs().sort_values(ascending=False).index)\n",
    "print(\"\n",
    "Вклад признаков в PC1 (по модулю):\")\n",
    "print(loadings_pc1)\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "explained.plot(kind=\"bar\")\n",
    "plt.title(\"Доля объясненной дисперсии по компонентам\")\n",
    "plt.ylabel(\"Explained variance ratio\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6da3f3",
   "metadata": {},
   "source": [
    "\n",
    "Если веса в PC1 близки по модулю и одного знака, то первая компонента описывает **общую яркость** объекта (сдвиг всех полос одновременно). \n",
    "Именно это часто объясняет большую долю дисперсии.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb92662",
   "metadata": {},
   "source": [
    "\n",
    "## 7. PCA: сравнение 3 и 4 компонент\n",
    "\n",
    "Проверим качество кластеризации при 3 и 4 PCA‑признаках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb868dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Подвыборка для ускорения\n",
    "rng = np.random.default_rng(42)\n",
    "sample_size = 20000\n",
    "sample_idx = rng.choice(len(X_scaled), size=sample_size, replace=False)\n",
    "y_sample = df_clean['class'].iloc[sample_idx].to_numpy()\n",
    "\n",
    "pca3 = PCA(n_components=3, random_state=42)\n",
    "X_pca3 = pca3.fit_transform(X_scaled)\n",
    "X_pca3_s = X_pca3[sample_idx]\n",
    "\n",
    "pca4 = PCA(n_components=4, random_state=42)\n",
    "X_pca4 = pca4.fit_transform(X_scaled)\n",
    "X_pca4_s = X_pca4[sample_idx]\n",
    "\n",
    "rows = []\n",
    "for name, Xs in [(\"PCA3\", X_pca3_s), (\"PCA4\", X_pca4_s)]:\n",
    "    km = KMeans(n_clusters=3, n_init=10, random_state=42).fit(Xs)\n",
    "    gmm = GaussianMixture(n_components=3, random_state=42).fit(Xs)\n",
    "    agg = AgglomerativeClustering(n_clusters=3, linkage='ward').fit(Xs)\n",
    "\n",
    "    for algo, lab in [(\"kmeans\", km.labels_), (\"gmm\", gmm.predict(Xs)), (\"agg\", agg.labels_)]:\n",
    "        rows.append({\n",
    "            \"pca\": name,\n",
    "            \"algo\": algo,\n",
    "            \"ARI\": adjusted_rand_score(y_sample, lab),\n",
    "            \"V\": v_measure_score(y_sample, lab),\n",
    "            \"silhouette\": silhouette_score(Xs, lab),\n",
    "        })\n",
    "\n",
    "pd.DataFrame(rows).sort_values([\"ARI\", \"V\"], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715c34a",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Подбор параметров и расстояний\n",
    "\n",
    "- KMeans и Ward‑кластеризация используют Евклидову метрику по умолчанию.\n",
    "- Для Agglomerative пробуем разные linkage.\n",
    "- Для DBSCAN подбираем `eps` по k‑distance и смотрим влияние метрики.\n",
    "\n",
    "Выбор метрики и linkage влияет на результат: например, `complete` лучше разделяет плотные группы, а `average` — более вытянутые.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cdc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Выбор лучшего linkage для аггломеративной кластеризации\n",
    "linkages = ['ward', 'complete', 'average']\n",
    "linkage_scores = []\n",
    "\n",
    "for link in linkages:\n",
    "    if link == 'ward':\n",
    "        model = AgglomerativeClustering(n_clusters=3, linkage=link)\n",
    "    else:\n",
    "        model = AgglomerativeClustering(n_clusters=3, linkage=link, metric='euclidean')\n",
    "    labels = model.fit_predict(X_pca3_s)\n",
    "    linkage_scores.append((link, silhouette_score(X_pca3_s, labels)))\n",
    "\n",
    "linkage_scores = pd.DataFrame(linkage_scores, columns=['linkage', 'silhouette'])\n",
    "linkage_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Подбор eps для DBSCAN\n",
    "subset = X_pca3_s[:5000]\n",
    "neigh = NearestNeighbors(n_neighbors=5).fit(subset)\n",
    "dists, _ = neigh.kneighbors(subset)\n",
    "k_dist = np.sort(dists[:, -1])\n",
    "\n",
    "eps_candidates = [np.percentile(k_dist, p) for p in (90, 95, 98)]\n",
    "\n",
    "rows = []\n",
    "for metric in ['euclidean', 'manhattan']:\n",
    "    for eps in eps_candidates:\n",
    "        db = DBSCAN(eps=float(eps), min_samples=10, metric=metric).fit(X_pca3_s)\n",
    "        labels = db.labels_\n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        if n_clusters <= 1:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"metric\": metric,\n",
    "            \"eps\": float(eps),\n",
    "            \"clusters\": n_clusters,\n",
    "            \"silhouette\": silhouette_score(X_pca3_s, labels),\n",
    "            \"ARI\": adjusted_rand_score(y_sample, labels),\n",
    "            \"V\": v_measure_score(y_sample, labels),\n",
    "        })\n",
    "\n",
    "dbscan_results = pd.DataFrame(rows)\n",
    "dbscan_results.sort_values(\"silhouette\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1bb3a",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Сравнение алгоритмов по числу кластеров\n",
    "\n",
    "Графики ниже показывают качество (силуэт, ARI, V‑мера) в зависимости от числа кластеров.\n",
    "Для DBSCAN по оси X указан **фактический** результат по числу кластеров при разных `eps`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fea293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Лучший linkage и DBSCAN-метрика\n",
    "best_linkage = linkage_scores.sort_values(\"silhouette\", ascending=False).iloc[0][\"linkage\"]\n",
    "best_dbscan_metric = None\n",
    "if not dbscan_results.empty:\n",
    "    best_dbscan_metric = dbscan_results.sort_values(\"silhouette\", ascending=False).iloc[0][\"metric\"]\n",
    "\n",
    "results = []\n",
    "for k in range(2, 7):\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42).fit(X_pca3_s)\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42).fit(X_pca3_s)\n",
    "    if best_linkage == 'ward':\n",
    "        agg = AgglomerativeClustering(n_clusters=k, linkage=best_linkage).fit(X_pca3_s)\n",
    "    else:\n",
    "        agg = AgglomerativeClustering(n_clusters=k, linkage=best_linkage, metric='euclidean').fit(X_pca3_s)\n",
    "\n",
    "    for name, labels in [\n",
    "        (\"kmeans\", km.labels_),\n",
    "        (\"gmm\", gmm.predict(X_pca3_s)),\n",
    "        (\"agg\", agg.labels_),\n",
    "    ]:\n",
    "        results.append({\n",
    "            \"algo\": name,\n",
    "            \"clusters\": k,\n",
    "            \"silhouette\": silhouette_score(X_pca3_s, labels),\n",
    "            \"ARI\": adjusted_rand_score(y_sample, labels),\n",
    "            \"V\": v_measure_score(y_sample, labels),\n",
    "        })\n",
    "\n",
    "# Добавим DBSCAN (eps -> фактическое число кластеров)\n",
    "if best_dbscan_metric is not None:\n",
    "    for _, row in dbscan_results[dbscan_results['metric'] == best_dbscan_metric].iterrows():\n",
    "        results.append({\n",
    "            \"algo\": \"dbscan\",\n",
    "            \"clusters\": int(row['clusters']),\n",
    "            \"silhouette\": row['silhouette'],\n",
    "            \"ARI\": row['ARI'],\n",
    "            \"V\": row['V'],\n",
    "        })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Графики метрик\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, metric in zip(axes, [\"silhouette\", \"ARI\", \"V\"]):\n",
    "    sns.lineplot(data=res_df.sort_values(\"clusters\"), x=\"clusters\", y=metric, hue=\"algo\", marker=\"o\", ax=ax)\n",
    "    ax.set_xlabel(\"Число кластеров\")\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(metric)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b367a8",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Лучшая модель и визуализация кластеров\n",
    "\n",
    "Из таблицы видно, что лучший результат даёт **GMM + PCA(3)** при k=3.\n",
    "Ниже визуализация: форма точек соответствует истинному классу, цвет — найденному кластеру.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Лучшая модель: GMM, k=3 на PCA(3)\n",
    "gmm_best = GaussianMixture(n_components=3, random_state=42).fit(X_pca3)\n",
    "labels_best_sample = gmm_best.predict(X_pca3_s)\n",
    "\n",
    "print(\"ARI:\", adjusted_rand_score(y_sample, labels_best_sample))\n",
    "print(\"V-measure:\", v_measure_score(y_sample, labels_best_sample))\n",
    "\n",
    "print(pd.crosstab(pd.Series(labels_best_sample, name='cluster'), pd.Series(y_sample, name='class')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Визуализация в 2D\n",
    "pca2 = PCA(n_components=2, random_state=42)\n",
    "X_pca2 = pca2.fit_transform(X_scaled)\n",
    "\n",
    "plot_idx = rng.choice(len(X_pca2), size=5000, replace=False)\n",
    "X_plot = X_pca2[plot_idx]\n",
    "\n",
    "labels_full = gmm_best.predict(X_pca3)\n",
    "labels_plot = labels_full[plot_idx]\n",
    "true_plot = df_clean['class'].iloc[plot_idx].to_numpy()\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    \"PC1\": X_plot[:, 0],\n",
    "    \"PC2\": X_plot[:, 1],\n",
    "    \"cluster\": labels_plot,\n",
    "    \"class\": true_plot,\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=plot_df, x=\"PC1\", y=\"PC2\", hue=\"cluster\", style=\"class\", s=25)\n",
    "plt.title(\"Истинные классы (форма) и найденные кластеры (цвет)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a72364",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Подгруппа: яркие объекты (g < 19)\n",
    "\n",
    "Проверим качество кластеризации на более ярких объектах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Подгруппа ярких объектов\n",
    "mask_bright = df_clean['g'] < 19\n",
    "X_bright = X_raw.loc[mask_bright]\n",
    "\n",
    "# применяем тот же preprocessing\n",
    "X_bright = X_bright.clip(lower, upper, axis=1)\n",
    "X_bright_scaled = scaler.transform(X_bright)\n",
    "X_bright_pca3 = pca3.transform(X_bright_scaled)\n",
    "\n",
    "y_bright = df_clean.loc[mask_bright, 'class']\n",
    "\n",
    "km_b = KMeans(n_clusters=3, n_init=10, random_state=42).fit(X_bright_pca3)\n",
    "labels_b = km_b.labels_\n",
    "\n",
    "print(\"Bright subset size:\", len(X_bright_pca3))\n",
    "print(\"ARI:\", adjusted_rand_score(y_bright, labels_b))\n",
    "print(\"V-measure:\", v_measure_score(y_bright, labels_b))\n",
    "print(pd.crosstab(pd.Series(labels_b, name='cluster'), pd.Series(y_bright, name='class')))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
